# -*- coding: utf-8 -*-
"""model_gan_colab_entrenado

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/184EqIaAJkR94Z4kl9OAOyqbljmrcIi-d

![Imgur](https://i.imgur.com/acSOZRh.png)

# Laboratorio N° 3
"""

# Commented out IPython magic to ensure Python compatibility.
#Importar librerias
import torch
import torch.nn as nn
from torch.nn import init
import torchvision
import torchvision.transforms as T
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.data import sampler
import torchvision.datasets as dset
import os
import numpy as np
import gdown
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec

# %matplotlib inline
plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots
plt.rcParams['image.interpolation'] = 'nearest'
plt.rcParams['image.cmap'] = 'gray'

# for auto-reloading external modules
# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython
#%load_ext autoreload
#%autoreload 2

#Toma un conjunto de imágenes y las muestra en una cuadrícula en una única figura utilizando la biblioteca Matplotlib
def show_images(images):
    images = np.reshape(images, [images.shape[0], -1])
    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))
    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))

    fig = plt.figure(figsize=(sqrtn, sqrtn))
    gs = gridspec.GridSpec(sqrtn, sqrtn)
    gs.update(wspace=0.05, hspace=0.05)

    for i, img in enumerate(images):
        ax = plt.subplot(gs[i])
        plt.axis('off')
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_aspect('equal')
        plt.imshow(img.reshape([sqrtimg,sqrtimg]))
    return

#normaliza las imágenes al rango [-1, 1], una práctica común en el preprocesamiento de datos para modelos de aprendizaj
def preprocess_img(x):
    return 2 * x - 1.0

#realiza la operación inversa, devolviendo las imágenes a su rango original
def deprocess_img(x):
    return (x + 1.0) / 2.0

#evaluar la precisión o similitud entre dos conjuntos de datos.
def rel_error(x,y):
    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))

#Cuenta la cantidad total de parámetros en un modelo de PyTorch.
def count_params(model):
    """Cuenta la cantidad de parámteros presentes en el grafo computacional """
    param_count = np.sum([np.prod(p.size()) for p in model.parameters()])
    return param_count

class ChunkSampler(sampler.Sampler):
   """Muestrea elementos secuencialmente desde algún desplazamiento.
    Argumentos:
        num_samples: Número de datos deseados
        start: Desplazamiento desde donde deberíamos comenzar la selección
    """
    def __init__(self, num_samples, start=0):
        self.num_samples = num_samples
        self.start = start

    def __iter__(self):
        return iter(range(self.start, self.start + self.num_samples))

    def __len__(self):
        return self.num_samples

#utiliza la biblioteca gdown para descargar un archivo desde Google Drive.
url = 'https://drive.google.com/uc?id=1WMVK8XB1FZiMNA0Y4U1X2gBonmJOAdk_'
output = 'gan-checks-tf.npz'
gdown.download(url, output, quiet=False)

#Carga conjuntos de datos de entrenamiento y validación utilizando PyTorch y DataLoader para el conjunto de datos MNIST
# Número de ejemplos de entrenamiento y validación
NUM_TRAIN = 50000
NUM_VAL = 5000

# Dimensión del ruido utilizado en el generador
NOISE_DIM = 96

# Tamaño del lote durante el entrenamiento
batch_size = 128

# Cargar el conjunto de datos de entrenamiento
mnist_train = dset.MNIST('./cs231n/datasets/MNIST_data', train=True, download=True,
                           transform=T.ToTensor())

# Crear un DataLoader para el conjunto de datos de entrenamiento
loader_train = DataLoader(mnist_train, batch_size=batch_size,
                          sampler=ChunkSampler(NUM_TRAIN, 0))

# Cargar el conjunto de datos de validación
mnist_val = dset.MNIST('./cs231n/datasets/MNIST_data', train=True, download=True,
                           transform=T.ToTensor())

# Crear un DataLoader para el conjunto de datos de validación
loader_val = DataLoader(mnist_val, batch_size=batch_size,
                        sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))


#imgs = loader_train.__iter__().next()[0].view(batch_size, 784).numpy().squeeze()
imgs = next(iter(loader_train))[0].view(batch_size, 784).numpy().squeeze()

# Mostrar las imágenes del lote
show_images(imgs)

#Define las arquitecturas del generador y el discriminador en una red GAN
#Inicializa los pesos de las capas convolucionales y de normalización
def initialize_weights(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):
        init.normal_(m.weight.data, 0.0, 0.02)
    elif isinstance(m, nn.BatchNorm2d):
        init.normal_(m.weight.data, 1.0, 0.02)
        init.constant_(m.bias.data, 0)

class Generator(nn.Module):
    def __init__(self, noise_dim=NOISE_DIM, image_size=28, num_channels=1):
        super(Generator, self).__init__()
        # Capa completamente conectada, seguida de capas deconvolucionales y normalización
        self.fc = nn.Linear(noise_dim, 1024)
        self.deconv1 = nn.ConvTranspose2d(1024, 128, kernel_size=7, stride=1, padding=0, bias=False)
        self.bn1 = nn.BatchNorm2d(128)
        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64)
        self.deconv3 = nn.ConvTranspose2d(64, num_channels, kernel_size=4, stride=2, padding=1, bias=False)
        self.apply(initialize_weights)

    def forward(self, z):
        # Operaciones de forward del generador
        x = self.fc(z)
        x = x.view(x.size(0), 1024, 1, 1)
        x = nn.functional.relu(self.bn1(self.deconv1(x)))
        x = nn.functional.relu(self.bn2(self.deconv2(x)))
        x = torch.tanh(self.deconv3(x))
        return x

class Discriminator(nn.Module):
    def __init__(self, image_size=28, num_channels=1):
        super(Discriminator, self).__init__()
        # Capas convolucionales y completamente conectadas del discriminador
        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=4, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(128)
        self.fc = nn.Linear(128 * (image_size // 4) * (image_size // 4), 1)
        self.apply(initialize_weights)

    def forward(self, x):
        # Operaciones de forward del discriminador
        x = nn.functional.leaky_relu(self.bn1(self.conv1(x)), 0.2)
        x = nn.functional.leaky_relu(self.bn2(self.conv2(x)), 0.2)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

def show_image(image):
    #Muestra la imagen como una matriz de 28x28 píxeles
    plt.imshow(image.reshape((28, 28)), cmap='viridis')
    # Desactiva los ejes para una presentación más limpia
    plt.axis('off')
    # Muestra la imagen
    plt.show()

#La función toma los componentes clave de la GAN (discriminador, generador, optimizadores, funciones de pérdida)
#y realiza el bucle de entrenamiento.
def run_a_gan(D, G, D_solver, G_solver, discriminator_loss, generator_loss, show_every=250,
              batch_size=128, noise_size=96, num_epochs=10):
     """
    Entrenar un GAN.

    D: discriminador
    G: generador
    D_solver: optimizador del discriminador
    G_solver: optimizador del generador
    discriminator_loss: función de pérdida del discriminador
    generator_loss: función de pérdida del generador
    show_every: imprimir estadísticas cada show_every iteraciones
    batch_size: tamaño del lote
    noise_size: tamaño del ruido de entrada al generador
    num_epochs: número de épocas de entrenamiento
    """
    iter_count = 0
    for epoch in range(num_epochs):
        for x, _ in loader_train:
            if len(x) != batch_size:
                continue
            D_solver.zero_grad()
            real_data = x.to(dtype=torch.float32)

            logits_real = D(2* (real_data - 0.5)).to(dtype=torch.float32)

            g_fake_seed = sample_noise(batch_size, noise_size)
            fake_images = G(g_fake_seed).detach()
            logits_fake = D(fake_images.view(batch_size, 1, 28, 28))

            d_total_error = discriminator_loss(logits_real, logits_fake)
            d_total_error.backward() # Backpropagation
            D_solver.step() # Optimization step

            G_solver.zero_grad()
            g_fake_seed = sample_noise(batch_size, noise_size)
            fake_images = G(g_fake_seed)

            gen_logits_fake = D(fake_images.view(batch_size, 1, 28, 28))
            g_error = generator_loss(gen_logits_fake)
            g_error.backward() # Backpropagation
            G_solver.step() # Optimization step

            if (iter_count % show_every == 0):
                print('Iter: {}, D: {:.4}, G:{:.4}'.format(iter_count,d_total_error.item(),g_error.item()))
                imgs_numpy = deprocess_img(fake_images.data.cpu().numpy())
                #show_images(imgs_numpy[0:16])
                show_image(imgs_numpy[0])
                plt.show()
                print()

            iter_count += 1

def sample_noise(batch_size, dim):
    """
    Genera un tensor de ruido aleatorio.

    batch_size: tamaño del lote
    dim: dimensión del tensor de ruido
    """
    return torch.randn(batch_size, dim)

# Crear modelos y optimizadores
D = Discriminator()
G = Generator()
D_solver = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))
G_solver = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))

# Funciones de pérdida
def discriminator_loss(logits_real, logits_fake):
    # Pérdida del discriminador (BCE)
    loss_real = nn.functional.binary_cross_entropy_with_logits(logits_real, torch.ones_like(logits_real))
    loss_fake = nn.functional.binary_cross_entropy_with_logits(logits_fake, torch.zeros_like(logits_fake))
    return loss_real + loss_fake

def generator_loss(logits_fake):
    # Pérdida del generador (BCE)
    return nn.functional.binary_cross_entropy_with_logits(logits_fake, torch.ones_like(logits_fake))

# Entrenar el GAN
run_a_gan(D, G, D_solver, G_solver, discriminator_loss, generator_loss, num_epochs=5)

# Generar una imagen aleatoria
with torch.no_grad():
    random_noise = sample_noise(1, NOISE_DIM)
    generated_image = G(random_noise)

# Despreprocesar la imagen y mostrarla
generated_image_numpy = deprocess_img(generated_image.squeeze().cpu().numpy())
show_image(generated_image_numpy)

# Guardar los pesos del generador
torch.save(G.state_dict(), 'generador_pesos_cpu.pth')